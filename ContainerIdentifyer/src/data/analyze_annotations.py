import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
import glob


# è®¾ç½®ä¸­æ–‡å­—ä½“ - è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# æˆ–è€…ä½¿ç”¨ç³»ç»Ÿå­—ä½“
import matplotlib
matplotlib.rcParams['font.family'] = 'sans-serif'
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']

class YOLOAnalyzer:
    def __init__(self, image_folder, label_folder):
        self.image_folder = image_folder
        self.label_folder = label_folder
        self.class_names = self.get_class_names()

    def get_class_names(self):
        """è·å–ç±»åˆ«åç§°ï¼Œéœ€è¦æ ¹æ®ä½ çš„æ•°æ®é›†ä¿®æ”¹"""
        # è¿™é‡Œéœ€è¦ä½ æä¾›å…·ä½“çš„ç±»åˆ«åç§°
        # ä¾‹å¦‚: ['dent', 'crack', 'rust', 'breakage']
        return ['damage']  # æš‚æ—¶ç”¨ä¸€ä¸ªé€šç”¨ç±»åˆ«

    def parse_yolo_annotation(self, label_path, img_width, img_height):
        """è§£æYOLOæ ¼å¼æ ‡æ³¨"""
        boxes = []
        with open(label_path, 'r') as f:
            for line in f.readlines():
                data = line.strip().split()
                if len(data) == 5:
                    class_id = int(data[0])
                    x_center = float(data[1])
                    y_center = float(data[2])
                    width = float(data[3])
                    height = float(data[4])

                    # è½¬æ¢ä¸ºç»å¯¹åæ ‡
                    x1 = int((x_center - width / 2) * img_width)
                    y1 = int((y_center - height / 2) * img_height)
                    x2 = int((x_center + width / 2) * img_width)
                    y2 = int((y_center + height / 2) * img_height)

                    boxes.append({
                        'class_id': class_id,
                        'class_name': self.class_names[class_id] if class_id < len(
                            self.class_names) else f'class_{class_id}',
                        'bbox': [x1, y1, x2, y2],
                        'relative_bbox': [x_center, y_center, width, height]
                    })
        return boxes

    def visualize_annotation(self, image_name, save_path=None):
        """å¯è§†åŒ–æ ‡æ³¨"""
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        image_path = os.path.join(self.image_folder, image_name)
        label_path = os.path.join(self.label_folder, os.path.splitext(image_name)[0] + '.txt')

        # è¯»å–å›¾ç‰‡
        image = cv2.imread(image_path)
        if image is None:
            print(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
            return None

        img_height, img_width = image.shape[:2]

        # è¯»å–æ ‡æ³¨
        if os.path.exists(label_path):
            boxes = self.parse_yolo_annotation(label_path, img_width, img_height)
        else:
            print(f"æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶: {label_path}")
            boxes = []

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        for box in boxes:
            x1, y1, x2, y2 = box['bbox']
            class_name = box['class_name']

            # ç»˜åˆ¶çŸ©å½¢
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)

            # ç»˜åˆ¶ç±»åˆ«æ ‡ç­¾
            label = f"{class_name}"
            cv2.putText(image, label, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # æ˜¾ç¤ºæˆ–ä¿å­˜
        if save_path:
            cv2.imwrite(save_path, image)
            print(f"ä¿å­˜å¯è§†åŒ–ç»“æœ: {save_path}")
            return image
        else:
            # è°ƒæ•´æ˜¾ç¤ºå¤§å°
            display_size = (800, 600)
            display_img = cv2.resize(image, display_size)
            cv2.imshow(f"Annotation: {image_name}", display_img)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
            return image

    def get_all_image_files(self):
        """è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶"""
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
        all_images = []
        for ext in image_extensions:
            all_images.extend(glob.glob(os.path.join(self.image_folder, ext)))
            all_images.extend(glob.glob(os.path.join(self.image_folder, ext.upper())))

        # åªè¿”å›æ–‡ä»¶å
        return [os.path.basename(img) for img in all_images]

    def batch_analyze_dataset(self, sample_ratio=0.1, max_samples=1000):
        """æ‰¹é‡åˆ†ææ‰€æœ‰æ ·æœ¬"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡åˆ†ææ•°æ®é›†...")

        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        all_images = self.get_all_image_files()
        print(f"ğŸ“ æ‰¾åˆ° {len(all_images)} å¼ å›¾ç‰‡")

        if not all_images:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼")
            return

        # è®¡ç®—éœ€è¦åˆ†æçš„æ ·æœ¬æ•°é‡
        sample_count = min(int(len(all_images) * sample_ratio), max_samples, len(all_images))
        print(f"ğŸ” åˆ†æ {sample_count} ä¸ªæ ·æœ¬ (æ€»æ•°: {len(all_images)})")

        # éšæœºé€‰æ‹©æ ·æœ¬ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if sample_count < len(all_images):
            import random
            sample_images = random.sample(all_images, sample_count)
        else:
            sample_images = all_images

        # ç»Ÿè®¡å˜é‡
        total_boxes = 0
        class_counts = Counter()
        bbox_sizes = []
        bbox_aspect_ratios = []
        image_sizes = []
        images_with_boxes = 0
        images_without_boxes = 0

        # è¿›åº¦è·Ÿè¸ª
        from tqdm import tqdm

        print("\nğŸ“Š åˆ†æè¿›åº¦:")
        for i, img_name in enumerate(tqdm(sample_images)):
            image_path = os.path.join(self.image_folder, img_name)
            label_path = os.path.join(self.label_folder, os.path.splitext(img_name)[0] + '.txt')

            # è¯»å–å›¾ç‰‡å°ºå¯¸
            image = cv2.imread(image_path)
            if image is not None:
                img_height, img_width = image.shape[:2]
                image_sizes.append((img_width, img_height))

            # åˆ†ææ ‡æ³¨æ–‡ä»¶
            if os.path.exists(label_path):
                try:
                    with open(label_path, 'r') as f:
                        lines = f.readlines()
                        if lines:
                            images_with_boxes += 1
                            total_boxes += len(lines)

                            for line in lines:
                                data = line.strip().split()
                                if len(data) == 5:
                                    class_id = int(data[0])
                                    width = float(data[3])
                                    height = float(data[4])

                                    class_counts[class_id] += 1
                                    bbox_sizes.append(width * height)
                                    bbox_aspect_ratios.append(width / height if height > 0 else 0)
                        else:
                            images_without_boxes += 1
                except Exception as e:
                    print(f"\nâŒ è¯»å–æ ‡æ³¨æ–‡ä»¶é”™è¯¯ {label_path}: {e}")
            else:
                images_without_boxes += 1

        # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡ç»“æœ
        self._print_detailed_statistics(
            total_boxes, class_counts, bbox_sizes, bbox_aspect_ratios,
            image_sizes, images_with_boxes, images_without_boxes, sample_count
        )

        # ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
        self._generate_visual_report(
            bbox_sizes, bbox_aspect_ratios, image_sizes, class_counts
        )

    def _print_detailed_statistics(self, total_boxes, class_counts, bbox_sizes,
                                   bbox_aspect_ratios, image_sizes, images_with_boxes,
                                   images_without_boxes, sample_count):
        """è¾“å‡ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ æ•°æ®é›†è¯¦ç»†ç»Ÿè®¡åˆ†ææŠ¥å‘Š")
        print("=" * 60)

        print(f"\nğŸ“ æ ·æœ¬ç»Ÿè®¡:")
        print(f"  åˆ†ææ ·æœ¬æ•°é‡: {sample_count}")
        print(f"  æœ‰æ ‡æ³¨çš„å›¾ç‰‡: {images_with_boxes} ({images_with_boxes / sample_count * 100:.1f}%)")
        print(f"  æ— æ ‡æ³¨çš„å›¾ç‰‡: {images_without_boxes} ({images_without_boxes / sample_count * 100:.1f}%)")
        print(f"  æ€»è¾¹ç•Œæ¡†æ•°é‡: {total_boxes}")
        print(f"  å¹³å‡æ¯å›¾è¾¹ç•Œæ¡†: {total_boxes / max(images_with_boxes, 1):.2f}")

        if image_sizes:
            avg_width = np.mean([size[0] for size in image_sizes])
            avg_height = np.mean([size[1] for size in image_sizes])
            print(f"  å¹³å‡å›¾ç‰‡å°ºå¯¸: {avg_width:.0f}Ã—{avg_height:.0f}")

        print(f"\nğŸ¯ ç±»åˆ«åˆ†å¸ƒ:")
        if class_counts:
            for class_id, count in class_counts.most_common():
                class_name = self.class_names[class_id] if class_id < len(self.class_names) else f'class_{class_id}'
                percentage = count / total_boxes * 100
                print(f"  {class_name} (ID: {class_id}): {count} ä¸ªå®ä¾‹ ({percentage:.1f}%)")
        else:
            print("  æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨ä¿¡æ¯")

        if bbox_sizes:
            print(f"\nğŸ“ è¾¹ç•Œæ¡†å°ºå¯¸åˆ†æ:")
            print(f"  å¹³å‡ç›¸å¯¹é¢ç§¯: {np.mean(bbox_sizes):.4f}")
            print(f"  é¢ç§¯æ ‡å‡†å·®: {np.std(bbox_sizes):.4f}")
            print(f"  å¹³å‡å®½é«˜æ¯”: {np.mean(bbox_aspect_ratios):.2f}")

            # ç›®æ ‡å°ºå¯¸åˆ†å¸ƒ
            small = sum(1 for s in bbox_sizes if s < 0.01)
            medium = sum(1 for s in bbox_sizes if 0.01 <= s < 0.1)
            large = sum(1 for s in bbox_sizes if s >= 0.1)
            total = len(bbox_sizes)

            print(f"  å°ç›®æ ‡(<0.01): {small} ä¸ª ({small / total * 100:.1f}%)")
            print(f"  ä¸­ç›®æ ‡(0.01-0.1): {medium} ä¸ª ({medium / total * 100:.1f}%)")
            print(f"  å¤§ç›®æ ‡(>=0.1): {large} ä¸ª ({large / total * 100:.1f}%)")

    def _generate_visual_report(self, bbox_sizes, bbox_aspect_ratios, image_sizes, class_counts):
        """ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š"""
        if not bbox_sizes:
            print("\nâŒ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š")
            return

        print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šä¸­...")

        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('é›†è£…ç®±ç ´æŸæ•°æ®é›†åˆ†ææŠ¥å‘Š', fontsize=16, fontweight='bold')

        # 1. è¾¹ç•Œæ¡†é¢ç§¯åˆ†å¸ƒ
        axes[0, 0].hist(bbox_sizes, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 0].set_title('è¾¹ç•Œæ¡†ç›¸å¯¹é¢ç§¯åˆ†å¸ƒ')
        axes[0, 0].set_xlabel('ç›¸å¯¹é¢ç§¯')
        axes[0, 0].set_ylabel('æ•°é‡')
        axes[0, 0].grid(True, alpha=0.3)

        # 2. å®½é«˜æ¯”åˆ†å¸ƒ
        axes[0, 1].hist(bbox_aspect_ratios, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')
        axes[0, 1].set_title('è¾¹ç•Œæ¡†å®½é«˜æ¯”åˆ†å¸ƒ')
        axes[0, 1].set_xlabel('å®½é«˜æ¯”')
        axes[0, 1].set_ylabel('æ•°é‡')
        axes[0, 1].grid(True, alpha=0.3)

        # 3. ç±»åˆ«åˆ†å¸ƒ
        if class_counts:
            classes = [f'Class {cid}' for cid in class_counts.keys()]
            counts = list(class_counts.values())
            axes[1, 0].bar(classes, counts, color='lightgreen', alpha=0.7, edgecolor='black')
            axes[1, 0].set_title('ç±»åˆ«åˆ†å¸ƒ')
            axes[1, 0].set_ylabel('å®ä¾‹æ•°é‡')
            axes[1, 0].tick_params(axis='x', rotation=45)

        # 4. å›¾ç‰‡å°ºå¯¸åˆ†å¸ƒ
        if image_sizes:
            widths = [size[0] for size in image_sizes]
            heights = [size[1] for size in image_sizes]
            axes[1, 1].scatter(widths, heights, alpha=0.5, color='purple')
            axes[1, 1].set_title('å›¾ç‰‡å°ºå¯¸åˆ†å¸ƒ')
            axes[1, 1].set_xlabel('å®½åº¦')
            axes[1, 1].set_ylabel('é«˜åº¦')
            axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        report_path = os.path.join(self.image_folder, 'dataset_analysis_report.png')
        plt.savefig(report_path, dpi=300, bbox_inches='tight')
        print(f"âœ… å¯è§†åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        # æ˜¾ç¤ºå›¾è¡¨
        plt.show()

    def batch_visualize_samples(self, num_samples=10, save_dir=None):
        """æ‰¹é‡å¯è§†åŒ–æ ·æœ¬"""
        all_images = self.get_all_image_files()

        if not all_images:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼")
            return

        # éšæœºé€‰æ‹©æ ·æœ¬
        import random
        sample_images = random.sample(all_images, min(num_samples, len(all_images)))

        print(f"\nğŸ–¼ï¸  æ‰¹é‡å¯è§†åŒ– {len(sample_images)} ä¸ªæ ·æœ¬...")

        if save_dir:
            os.makedirs(save_dir, exist_ok=True)

        for i, img_name in enumerate(sample_images):
            print(f"  [{i + 1}/{len(sample_images)}] å¤„ç†: {img_name}")

            if save_dir:
                save_path = os.path.join(save_dir, f"visualized_{img_name}")
                self.visualize_annotation(img_name, save_path)
            else:
                self.visualize_annotation(img_name)


def main():
    # é…ç½®è·¯å¾„
    image_folder = r"D:\ContainerIdentifyer\data\images"
    label_folder = r"D:\ContainerIdentifyer\data\labels"  # ä½ éœ€è¦ç¡®è®¤æ ‡æ³¨æ–‡ä»¶è·¯å¾„

    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_folder):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {image_folder}")
        return
    if not os.path.exists(label_folder):
        print(f"âŒ æ ‡æ³¨æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {label_folder}")
        return

    analyzer = YOLOAnalyzer(image_folder, label_folder)

    # æ‰¹é‡åˆ†ææ‰€æœ‰æ ·æœ¬ï¼ˆåˆ†æ10%çš„æ ·æœ¬ï¼Œæœ€å¤š1000ä¸ªï¼‰
    analyzer.batch_analyze_dataset(sample_ratio=0.1, max_samples=1000)

    # æ‰¹é‡å¯è§†åŒ–ä¸€äº›æ ·æœ¬ï¼ˆå¯é€‰ï¼‰
    # analyzer.batch_visualize_samples(num_samples=5, save_dir="./visualized_samples")


if __name__ == "__main__":
    main()